# Projet Darija App

## ğŸ“‹ Vue d'ensemble

Ce projet est dÃ©diÃ© Ã  l'analyse et au traitement du dataset "Darija-SFT-Mixture", un ensemble de donnÃ©es linguistiques en dialecte marocain (Darija). Le projet comprend des outils pour tÃ©lÃ©charger, convertir et analyser ces donnÃ©es, avec une architecture modulaire et bien organisÃ©e.

## ğŸ—‚ï¸ Structure du Projet

```
darija_app/
â”œâ”€â”€ notebooks/                      # Notebooks d'analyse
â”‚   â”œâ”€â”€ analyse_darija.ipynb        # Analyse dÃ©taillÃ©e des donnÃ©es
â”‚   â”œâ”€â”€ cleaned_translations.json   # Traductions nettoyÃ©es
â”‚   â”œâ”€â”€ structured_translations.json # Traductions structurÃ©es
â”‚   â””â”€â”€ invalid_translations.json   # Traductions invalides
â”‚
â”œâ”€â”€ data_Darija-SFT-Mixture/        # Dossier principal des donnÃ©es
â”‚   â”œâ”€â”€ notebooks/                  # Notebooks supplÃ©mentaires
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/                      # Tests unitaires et d'intÃ©gration
â”‚   â”‚
â”‚   â”œâ”€â”€ darija_modules/             # Modules Python du projet
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Initialisation du package
â”‚   â”‚   â”œâ”€â”€ dataset_statistics.py   # Module d'analyse statistique
â”‚   â”‚   â”œâ”€â”€ parquet_downloader.py   # Module de tÃ©lÃ©chargement
â”‚   â”‚   â””â”€â”€ pipeline_automatisation.py # Orchestration du pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ darija_data/                # DonnÃ©es du projet
â”‚   â”‚   â”œâ”€â”€ parquet_files/          # Fichiers Parquet bruts
â”‚   â”‚   â”œâ”€â”€ csv_files/              # Fichiers CSV convertis
â”‚   â”‚   â”œâ”€â”€ execution_logs/         # Journaux d'exÃ©cution
â”‚   â”‚   â””â”€â”€ dataset_statistics/     # Statistiques du dataset
â”‚   â”‚
â”‚   â”œâ”€â”€ project_dependencies.txt    # DÃ©pendances du projet
â”‚   â””â”€â”€ huggingface_token.env       # Configuration des tokens
â”‚
â”œâ”€â”€ venv/                           # Environnement virtuel Python
â””â”€â”€ suivi.txt                       # Journal des modifications
```

## ğŸ” Description des Composants

### 1. Modules Python (`darija_modules/`)

#### `dataset_statistics.py`
- **Fonction** : RÃ©cupÃ¨re et analyse les statistiques du dataset via l'API Hugging Face
- **Classe principale** : `DarijaStatsAPI`
- **FonctionnalitÃ©s** :
  - RÃ©cupÃ©ration des mÃ©tadonnÃ©es du dataset
  - GÃ©nÃ©ration de statistiques dÃ©taillÃ©es
  - CrÃ©ation de rapports en format Markdown
  - Sauvegarde des rÃ©sultats en JSON

#### `parquet_downloader.py`
- **Fonction** : TÃ©lÃ©charge les fichiers Parquet et les convertit en CSV
- **Classe principale** : `DarijaParquetDownloader`
- **FonctionnalitÃ©s** :
  - TÃ©lÃ©chargement des fichiers via l'API Hugging Face
  - Conversion automatique de Parquet vers CSV
  - Gestion optimisÃ©e de l'espace disque

#### `pipeline_automatisation.py`
- **Fonction** : Orchestre l'exÃ©cution des diffÃ©rents modules
- **Classe principale** : `DarijaPipeline`
- **FonctionnalitÃ©s** :
  - Configuration de l'environnement d'exÃ©cution
  - ExÃ©cution sÃ©quentielle des modules
  - Gestion des erreurs et des dÃ©pendances
  - Mesure des performances

### 2. DonnÃ©es (`darija_data/`)

#### `parquet_files/`
- Stockage temporaire des fichiers Parquet tÃ©lÃ©chargÃ©s
- Ces fichiers sont supprimÃ©s aprÃ¨s conversion en CSV

#### `csv_files/`
- Fichiers CSV convertis Ã  partir des fichiers Parquet
- Format plus accessible pour l'analyse

#### `execution_logs/`
- Journaux dÃ©taillÃ©s de l'exÃ©cution du pipeline
- Suivi des erreurs et des performances

#### `dataset_statistics/`
- Statistiques du dataset au format JSON
- Rapports d'analyse au format Markdown

### 3. Notebooks d'analyse (`notebooks/`)

#### `analyse_darija.ipynb`
- Analyse approfondie des donnÃ©es Darija
- Visualisations et statistiques dÃ©taillÃ©es
- Traitement et nettoyage des traductions

#### Fichiers JSON
- `cleaned_translations.json` : Traductions nettoyÃ©es
- `structured_translations.json` : Traductions structurÃ©es
- `invalid_translations.json` : Traductions invalides identifiÃ©es

## ğŸš€ Fonctionnement du Pipeline

Le pipeline complet s'exÃ©cute dans l'ordre suivant :

1. **Initialisation** : Configuration des dossiers et du systÃ¨me de logs
2. **Statistiques** : RÃ©cupÃ©ration et analyse des mÃ©tadonnÃ©es du dataset
3. **TÃ©lÃ©chargement** : Obtention des fichiers Parquet depuis Hugging Face
4. **Conversion** : Transformation des fichiers Parquet en CSV
5. **Analyse** : Traitement et analyse des donnÃ©es via les notebooks

## ğŸ“Š Dataset Darija-SFT-Mixture

- **Source** : MBZUAI-Paris/Darija-SFT-Mixture sur Hugging Face
- **Contenu** : Conversations et instructions en dialecte marocain (Darija)
- **Format** : Fichiers Parquet (2 fichiers d'entraÃ®nement)
- **Taille** : Environ 458K Ã©chantillons
- **Structure** :
  - `dataset` : Nom du dataset source
  - `id` : Identifiant unique
  - `messages` : Liste de messages (contenu, rÃ´le)
  - `direction` : Direction de la traduction
  - `metadata` : MÃ©tadonnÃ©es supplÃ©mentaires

## ğŸ› ï¸ Installation et Utilisation

1. **Cloner le dÃ©pÃ´t** :
   ```bash
   git clone [URL_DU_REPO]
   cd darija_app
   ```

2. **Configurer l'environnement** :
   ```bash
   python -m venv venv --system-site-packages
   source venv/bin/activate  # Linux/Mac
   # ou
   venv\Scripts\activate.bat  # Windows
   ```

3. **Installer les dÃ©pendances** :
   ```bash
   pip install -r data_Darija-SFT-Mixture/project_dependencies.txt
   ```

4. **Configurer le token Hugging Face** :
   - CrÃ©er un fichier `huggingface_token.env` avec votre token

5. **ExÃ©cuter le pipeline** :
   ```bash
   cd data_Darija-SFT-Mixture
   python -m darija_modules.pipeline_automatisation
   ```

6. **Analyser les donnÃ©es** :
   - Ouvrir le notebook `notebooks/analyse_darija.ipynb` avec Jupyter

## ğŸ“ Journal des Modifications

Le fichier `suivi.txt` contient un journal dÃ©taillÃ© des modifications apportÃ©es au projet, avec des informations sur les dÃ©cisions de conception et les amÃ©liorations successives.

## ğŸ”„ Flux de Travail

```mermaid
graph TD
    A[Initialisation] --> B[Statistiques du Dataset]
    B --> C[TÃ©lÃ©chargement des fichiers Parquet]
    C --> D[Conversion en CSV]
    D --> E[Analyse des donnÃ©es]
    E --> F[GÃ©nÃ©ration de rapports]
```

## ğŸ“ˆ RÃ©sultats

Les analyses produites par ce projet permettent de :
- Comprendre la structure et la distribution des donnÃ©es en Darija
- Identifier les modÃ¨les linguistiques et les particularitÃ©s du dialecte
- PrÃ©parer les donnÃ©es pour des applications de traitement du langage naturel
- GÃ©nÃ©rer des statistiques dÃ©taillÃ©es sur le corpus linguistique

## ğŸ¤ Contribution

Pour contribuer Ã  ce projet :
1. Forker le dÃ©pÃ´t
2. CrÃ©er une branche pour votre fonctionnalitÃ©
3. Soumettre une pull request avec une description dÃ©taillÃ©e

## ğŸ“„ Licence

Ce projet est distribuÃ© sous licence [Ã  spÃ©cifier]. 